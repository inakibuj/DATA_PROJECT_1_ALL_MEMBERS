import time
import json
import requests
from kafka import KafkaProducer
import schedule
from datetime import datetime

# --- CONFIGURACI√ìN ---
# Usamos el dominio oficial de OpenDataSoft Valencia
BASE_URL = "https://valencia.opendatasoft.com"

# URL 1: Contaminaci√≥n
URL_POLLUTION = f"{BASE_URL}/api/explore/v2.1/catalog/datasets/estacions-contaminacio-atmosferiques-estaciones-contaminacion-atmosfericas/records?limit=20"

# URL 2: Meteorolog√≠a (Clima)
URL_WEATHER = f"{BASE_URL}/api/explore/v2.1/catalog/datasets/estacions-atmosferiques-estaciones-atmosfericas/records?limit=20"

# Configuraci√≥n Kafka
KAFKA_SERVER = "kafka:9092"

# Definimos dos t√≥picos diferentes para mantener el orden
TOPIC_POLLUTION = "valencia_pollution"
TOPIC_WEATHER = "valencia_weather"

def get_kafka_producer():
    # Intentamos conectar hasta que Kafka est√© listo (Docker a veces tarda en arrancar)
    producer = None
    while not producer:
        try:
            producer = KafkaProducer(
                bootstrap_servers=[KAFKA_SERVER],
                value_serializer=lambda x: json.dumps(x).encode('utf-8')
            )
            print("‚úÖ Conexi√≥n exitosa con Kafka")
        except Exception as e:
            print(f"‚è≥ Esperando a Kafka... ({e})")
            time.sleep(5)
    return producer

producer = get_kafka_producer()

def fetch_and_send(url, topic_name, data_type):
    """
    Funci√≥n gen√©rica para descargar de la API y enviar a Kafka
    """
    print(f"üì• Consultando API de {data_type}...")
    try:
        response = requests.get(url)
        if response.status_code == 200:
            data = response.json()
            
            # La API devuelve una lista dentro de 'results'
            records = data.get('results', [])
            
            print(f"   -> Encontrados {len(records)} registros.")
            
            for record in records:
                # A√±adimos marca de tiempo de ingesti√≥n
                record['ingestion_timestamp'] = datetime.now().isoformat()
                record['data_type'] = data_type # Etiqueta extra por si acaso
                
                # ENVIAR A KAFKA
                producer.send(topic_name, value=record)
            
            producer.flush()
            print(f"üì§ Datos de {data_type} enviados a Kafka correctamente.")
            
        else:
            print(f"‚ùå Error HTTP {response.status_code} al consultar {data_type}")
            
    except Exception as e:
        print(f"‚ùå Error de conexi√≥n: {e}")

def job():
    print(f"\n--- INICIO CICLO {datetime.now().strftime('%H:%M:%S')} ---")
    # 1. Traer Contaminaci√≥n
    fetch_and_send(URL_POLLUTION, TOPIC_POLLUTION, "contaminacion")
    
    # 2. Traer Clima
    fetch_and_send(URL_WEATHER, TOPIC_WEATHER, "clima")
    print("--- FIN CICLO ---\n")

# --- EJECUCI√ìN ---
# Ejecutar una vez al arrancar
job()

# Programar cada 10 minutos (600 segundos)
schedule.every(10).minutes.do(job)

while True:
    schedule.run_pending()
    time.sleep(1)
    